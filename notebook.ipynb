{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"polygon_areas\" does not exist\nLINE 2:     INSERT INTO polygon_areas (id, area_id, name, coordinate...\n                        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m conn \u001b[38;5;241m=\u001b[39m psycopg2\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mDB_CONFIG)\n\u001b[0;32m      9\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m---> 11\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m     12\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    INSERT INTO polygon_areas (id, area_id, name, coordinate, created_at)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    VALUES (%s, %s, %s, %s, NOW())\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[0;32m     16\u001b[0m     (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mUndefinedTable\u001b[0m: relation \"polygon_areas\" does not exist\nLINE 2:     INSERT INTO polygon_areas (id, area_id, name, coordinate...\n                        ^\n"
     ]
    }
   ],
   "source": [
    "DB_CONFIG = {\n",
    "    \"dbname\": \"tracking_db\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO polygon_areas (id, area_id, name, coordinate, created_at)\n",
    "    VALUES (%s, %s, %s, %s, NOW())\n",
    "    \"\"\",\n",
    "    (1, 1, 'test', 'testing')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data inserted successfully!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "DB_CONFIG = {\n",
    "    \"dbname\": \"synapsis\",\n",
    "    \"user\": \"postgres\",\n",
    "    \"password\": \"123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\n",
    "    \"\"\"\n",
    "    INSERT INTO public.polygon_areas (area_id, name, coordinate)\n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\",\n",
    "    (2, 'Malioboro_10_Kepatihan', '[(1200, 150), (700, 150), (700, 300), (1200, 300)]')\n",
    ")\n",
    "\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"✅ Data inserted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"polygon_areas\" does not exist\nLINE 2:     INSERT INTO polygon_areas (id, area_id, name, coordinate...\n                        ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m    INSERT INTO polygon_areas (id, area_id, name, coordinate, created_at)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m    VALUES (%s, %s, %s, %s, NOW())\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m,\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mUndefinedTable\u001b[0m: relation \"polygon_areas\" does not exist\nLINE 2:     INSERT INTO polygon_areas (id, area_id, name, coordinate...\n                        ^\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AIZEN Data\\AppData\\Roaming\\Python\\Python312\\site-packages\\deep_sort_realtime\\embedder\\embedder_pytorch.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(model_wts_path))\n"
     ]
    }
   ],
   "source": [
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "tracker = DeepSort(max_age=30)  # Keeps tracking for 30 frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from norfair import Detection, Tracker\n",
    "\n",
    "tracker = Tracker(distance_function=\"euclidean\", distance_threshold=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sort.sort import *\n",
    "\n",
    "#create instance of SORT\n",
    "mot_tracker = Sort() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Dummy detections: [[        100         100         200         200         0.9           0]]\n",
      "Tracked objects: []\n"
     ]
    }
   ],
   "source": [
    "from byte_tracker import BYTETracker  # Import ByteTrack\n",
    "from types import SimpleNamespace\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "model = YOLO('./models/yolov5nu.onnx')\n",
    "args = SimpleNamespace(track_thresh=0.2, track_buffer=50, match_thresh=0.2, mot20=False)\n",
    "\n",
    "# Initialize ByteTrack tracker\n",
    "tracker = BYTETracker(args)\n",
    "\n",
    "# Dummy detection for testing\n",
    "dummy_detections = np.array([[100, 100, 200, 200, 0.9, 0]], dtype=np.float32)\n",
    "\n",
    "# Print the dummy detections\n",
    "print(\"Dummy detections:\", dummy_detections)\n",
    "\n",
    "# Update tracker with dummy detections and print the result\n",
    "tracked_objects = tracker.update(torch.tensor(dummy_detections), (720, 1280), (720, 1280))\n",
    "\n",
    "# Print the tracked objects\n",
    "print(\"Tracked objects:\", tracked_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading models\\yolov5nu.onnx for ONNX Runtime inference...\n",
      "Using ONNX Runtime CPUExecutionProvider\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "axes don't match array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m dummy_detections \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Run tracking\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrack(source\u001b[38;5;241m=\u001b[39mdummy_detections, persist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Print tracked objects\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTracked objects:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:607\u001b[0m, in \u001b[0;36mModel.track\u001b[1;34m(self, source, stream, persist, **kwargs)\u001b[0m\n\u001b[0;32m    605\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# batch-size 1 for tracking in videos\u001b[39;00m\n\u001b[0;32m    606\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrack\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 607\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\model.py:560\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prompts \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_prompts\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# for SAM-type models\u001b[39;00m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mset_prompts(prompts)\n\u001b[1;32m--> 560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39mpredict_cli(source\u001b[38;5;241m=\u001b[39msource) \u001b[38;5;28;01mif\u001b[39;00m is_cli \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor(source\u001b[38;5;241m=\u001b[39msource, stream\u001b[38;5;241m=\u001b[39mstream)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:175\u001b[0m, in \u001b[0;36mBasePredictor.__call__\u001b[1;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_inference(source, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m gen\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:257\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# Preprocess\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m--> 257\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(im0s)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:128\u001b[0m, in \u001b[0;36mBasePredictor.preprocess\u001b[1;34m(self, im)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_tensor:\n\u001b[0;32m    127\u001b[0m     im \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform(im))\n\u001b[1;32m--> 128\u001b[0m     im \u001b[38;5;241m=\u001b[39m im[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mtranspose((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))  \u001b[38;5;66;03m# BGR to RGB, BHWC to BCHW, (n, 3, h, w)\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     im \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(im)  \u001b[38;5;66;03m# contiguous\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     im \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(im)\n",
      "\u001b[1;31mValueError\u001b[0m: axes don't match array"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO model (ensure it's a compatible tracking model)\n",
    "model = YOLO('./models/yolov5nu.onnx')\n",
    "\n",
    "# Dummy detection: (x1, y1, x2, y2, confidence, class)\n",
    "dummy_detections = np.array([[100, 100, 200, 200, 0.9, 0]], dtype=np.float32)\n",
    "\n",
    "# Run tracking\n",
    "results = model.track(source=dummy_detections, persist=True)\n",
    "\n",
    "# Print tracked objects\n",
    "print(\"Tracked objects:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dummy_detections: (1, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of dummy_detections:\", dummy_detections.shape)  # Should be (1,6) or (1,8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracked objects: []\n"
     ]
    }
   ],
   "source": [
    "frame_size = (720, 1280)\n",
    "x1, y1, x2, y2 = 100 / frame_size[1], 100 / frame_size[0], 200 / frame_size[1], 200 / frame_size[0]\n",
    "dummy_detections = np.array([[x1, y1, x2, y2, 0.9, 0]], dtype=np.float32)\n",
    "tracked_objects = tracker.update(dummy_detections, frame_size, frame_size)\n",
    "print(\"Tracked objects:\", tracked_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracked_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov5su.pt to 'yolov5su.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17.7M/17.7M [00:10<00:00, 1.79MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.76  Python-3.12.7 torch-2.5.1+cpu CPU (AMD Ryzen 7 7730U with Radeon Graphics)\n",
      "YOLOv5s summary (fused): 84 layers, 9,142,496 parameters, 0 gradients, 24.0 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov5su.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (17.7 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxslim'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  AutoUpdate skipped (offline)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.17.0 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxslim'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.5s, saved as 'yolov5su.onnx' (35.1 MB)\n",
      "\n",
      "Export complete (2.3s)\n",
      "Results saved to \u001b[1mC:\\Users\\AIZEN Data\\vscode file\\Synapsis\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov5su.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov5su.onnx imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'yolov5su.onnx'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv8m model (default PyTorch format)\n",
    "model = YOLO(\"yolov5su.pt\")\n",
    "\n",
    "# Export to ONNX format\n",
    "model.export(format=\"onnx\")  # This will create 'yolov8m.onnx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\AIZEN Data/.cache\\torch\\hub\\ultralytics_yolov5_v7.0\n",
      "YOLOv5  2025-2-19 Python-3.12.7 torch-2.5.1+cpu CPU\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...\n",
      "100%|██████████| 40.8M/40.8M [00:24<00:00, 1.75MB/s]\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'AutoShape' object has no attribute 'export'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Download dan load model YOLOv5n (nano) pretrained\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124multralytics/yolov5:v7.0\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolov5m\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Model YOLOv5n\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124monnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1933\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AutoShape' object has no attribute 'export'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Download dan load model YOLOv5n (nano) pretrained\n",
    "model = torch.hub.load('ultralytics/yolov5:v7.0', 'yolov5m')  # Model YOLOv5n\n",
    "model.export(format='onnx') # Model YOLOv5n\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
